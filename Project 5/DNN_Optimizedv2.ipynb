{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1st DNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarvan0506/AI/blob/Dev/Project%204/DNN_Optimized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "# install and import keras for neural network design and implementation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# import keras objects for Convolution and import the dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "9fc766b5-aee7-4e70-d4bd-7f89f5a56f12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# load the datset into train and test sets"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "b9acdeb7-a6d9-4d1e-fffb-e77eb46647cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])\n",
        "\n",
        "# plotting a sample as image to get a visual feel"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f346f15efd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
        "\n",
        "# reshaping the dataset to Convolution format, X_train.shape[0] --> # of images, (28, 28) --> input image resolution, 1 - # of channels(the image itself)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# converting the values into greyscale values."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "04295d85-bf6b-4899-d840-81fdb26af201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "1993ae2a-2ab0-4d34-dd69-d00a327064da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV-W5WqTnnWw",
        "colab_type": "text"
      },
      "source": [
        "Now we are going to optimize the network step by step to achieve max validation accuracy with less no. of parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g8U9sjkwr2a",
        "colab_type": "text"
      },
      "source": [
        "# Iteration 1: Network with less than 15k parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mKO3HnNwkcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f57181d2-1d15-4279-c228-ef4681959b2a"
      },
      "source": [
        "\n",
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) # output 26\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))  # output 24\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # output 11\n",
        "model.add(Convolution2D(11, 1, activation='relu')) # output 11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 9\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 7\n",
        "\n",
        "\n",
        "model.add(Convolution2D(7, 1, activation='relu')) # output 7\n",
        "model.add(Convolution2D(10, 7))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0AQ5G-0w7M5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "4ee9dd9e-f52a-493d-e556-fb730fe5eb14"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_82 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_85 (Conv2D)           (None, 11, 11, 11)        187       \n",
            "_________________________________________________________________\n",
            "conv2d_86 (Conv2D)           (None, 9, 9, 16)          1600      \n",
            "_________________________________________________________________\n",
            "conv2d_87 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_88 (Conv2D)           (None, 7, 7, 7)           119       \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 1, 1, 10)          3440      \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,466\n",
            "Trainable params: 12,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQjEHGcSw7QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# determining model evaluation metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuGOqqhYxD97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "fec941cf-5344-48f6-ec90-faf949e3c054"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=20, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "# training"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 13s 224us/step - loss: 0.1903 - acc: 0.9428 - val_loss: 0.0633 - val_acc: 0.9809\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0714 - acc: 0.9785 - val_loss: 0.0537 - val_acc: 0.9828\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0548 - acc: 0.9829 - val_loss: 0.0467 - val_acc: 0.9849\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0465 - acc: 0.9861 - val_loss: 0.0466 - val_acc: 0.9844\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0407 - acc: 0.9869 - val_loss: 0.0348 - val_acc: 0.9887\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0353 - acc: 0.9889 - val_loss: 0.0326 - val_acc: 0.9892\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0323 - acc: 0.9901 - val_loss: 0.0365 - val_acc: 0.9880\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0283 - acc: 0.9913 - val_loss: 0.0304 - val_acc: 0.9903\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0268 - acc: 0.9912 - val_loss: 0.0392 - val_acc: 0.9879\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0245 - acc: 0.9923 - val_loss: 0.0359 - val_acc: 0.9892\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0222 - acc: 0.9924 - val_loss: 0.0322 - val_acc: 0.9896\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0208 - acc: 0.9933 - val_loss: 0.0325 - val_acc: 0.9894\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0188 - acc: 0.9937 - val_loss: 0.0366 - val_acc: 0.9885\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0184 - acc: 0.9940 - val_loss: 0.0390 - val_acc: 0.9901\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0362 - val_acc: 0.9883\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0152 - acc: 0.9950 - val_loss: 0.0397 - val_acc: 0.9886\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0141 - acc: 0.9953 - val_loss: 0.0451 - val_acc: 0.9881\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0142 - acc: 0.9949 - val_loss: 0.0335 - val_acc: 0.9899\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0149 - acc: 0.9945 - val_loss: 0.0349 - val_acc: 0.9895\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 11s 192us/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.0361 - val_acc: 0.9901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f344465b588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv28h_a778Zl",
        "colab_type": "text"
      },
      "source": [
        "## Inference\n",
        "The model is performing good but doesn't reach 99.4% of validation accuracy, There is a significant gap between the training and validation accuracy which is a sign of over-fitting. We can add BN, Dropout etc step-by-step to reduce over-fitting and improve on this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyGRHqXd9Un2",
        "colab_type": "text"
      },
      "source": [
        "# Iteration 2: Adding Batch Normalization and Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6572ff49-946f-4e8b-b8f5-0c07dcad7c80"
      },
      "source": [
        "\n",
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # output 11\n",
        "model.add(Convolution2D(11, 1, activation='relu')) # output 11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(7, 1, activation='relu')) # output 7\n",
        "model.add(Convolution2D(10, 7))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "          \n",
        "model.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_90 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_91 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 11, 11, 11)        187       \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 9, 9, 16)          1600      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           (None, 7, 7, 7)           119       \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           (None, 1, 1, 10)          3440      \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,786\n",
            "Trainable params: 12,626\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyGaXB3m91Do",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "7b954c8c-aa4d-4d53-94d5-43acf6d56ec3"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# determining model evaluation metrics\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=20, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "# training"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 22s 373us/step - loss: 0.2041 - acc: 0.9354 - val_loss: 0.0505 - val_acc: 0.9827\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 20s 334us/step - loss: 0.0649 - acc: 0.9792 - val_loss: 0.0386 - val_acc: 0.9866\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 20s 332us/step - loss: 0.0518 - acc: 0.9839 - val_loss: 0.0403 - val_acc: 0.9878\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 20s 332us/step - loss: 0.0453 - acc: 0.9854 - val_loss: 0.0324 - val_acc: 0.9896\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 20s 334us/step - loss: 0.0409 - acc: 0.9872 - val_loss: 0.0310 - val_acc: 0.9904\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 20s 330us/step - loss: 0.0364 - acc: 0.9886 - val_loss: 0.0257 - val_acc: 0.9908\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 20s 331us/step - loss: 0.0333 - acc: 0.9895 - val_loss: 0.0369 - val_acc: 0.9871\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0318 - acc: 0.9902 - val_loss: 0.0313 - val_acc: 0.9898\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 19s 325us/step - loss: 0.0291 - acc: 0.9907 - val_loss: 0.0320 - val_acc: 0.9901\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0289 - acc: 0.9910 - val_loss: 0.0253 - val_acc: 0.9918\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0269 - acc: 0.9913 - val_loss: 0.0285 - val_acc: 0.9909\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0259 - acc: 0.9920 - val_loss: 0.0283 - val_acc: 0.9906\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0246 - acc: 0.9921 - val_loss: 0.0274 - val_acc: 0.9905\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 20s 334us/step - loss: 0.0228 - acc: 0.9925 - val_loss: 0.0306 - val_acc: 0.9910\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 19s 324us/step - loss: 0.0225 - acc: 0.9923 - val_loss: 0.0310 - val_acc: 0.9911\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0218 - acc: 0.9930 - val_loss: 0.0266 - val_acc: 0.9918\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 20s 325us/step - loss: 0.0212 - acc: 0.9929 - val_loss: 0.0277 - val_acc: 0.9916\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 19s 321us/step - loss: 0.0202 - acc: 0.9931 - val_loss: 0.0247 - val_acc: 0.9921\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 19s 321us/step - loss: 0.0197 - acc: 0.9935 - val_loss: 0.0262 - val_acc: 0.9913\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0190 - acc: 0.9937 - val_loss: 0.0264 - val_acc: 0.9915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3410284cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOH3lVTWDSDb",
        "colab_type": "text"
      },
      "source": [
        "## Inference\n",
        "Now we can see the over-fitting is reduced with the help of BN and Dropout. But we have not still reached the target accuracy. Let us try using dynamic learning rate and increase the dropout rate a liitle bit as there is still some over-fitting issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx3eaKkbDoAA",
        "colab_type": "text"
      },
      "source": [
        "# Iteration 3: Adding dynamic learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRahPQeQFDD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7cbeb52b-e25d-4923-a280-8cf2cb091fbb"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # output 11\n",
        "model.add(Convolution2D(11, 1, activation='relu')) # output 11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(7, 1, activation='relu')) # output 7\n",
        "model.add(Convolution2D(10, 7))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "          \n",
        "model.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_122 (Conv2D)          (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_123 (Conv2D)          (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_124 (Conv2D)          (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_125 (Conv2D)          (None, 11, 11, 11)        187       \n",
            "_________________________________________________________________\n",
            "conv2d_126 (Conv2D)          (None, 9, 9, 16)          1600      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_127 (Conv2D)          (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_128 (Conv2D)          (None, 7, 7, 7)           119       \n",
            "_________________________________________________________________\n",
            "conv2d_129 (Conv2D)          (None, 1, 1, 10)          3440      \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,786\n",
            "Trainable params: 12,626\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO_2rDJgDk0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b7c64e0-2940-45aa-cbc6-1dcccc17623b"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 25s 410us/step - loss: 0.1680 - acc: 0.9468 - val_loss: 0.0600 - val_acc: 0.9804\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 20s 336us/step - loss: 0.0655 - acc: 0.9794 - val_loss: 0.0433 - val_acc: 0.9855\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 20s 333us/step - loss: 0.0523 - acc: 0.9835 - val_loss: 0.0968 - val_acc: 0.9695\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0437 - acc: 0.9870 - val_loss: 0.0267 - val_acc: 0.9923\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 20s 334us/step - loss: 0.0378 - acc: 0.9881 - val_loss: 0.0314 - val_acc: 0.9900\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 20s 336us/step - loss: 0.0346 - acc: 0.9888 - val_loss: 0.0273 - val_acc: 0.9912\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 20s 328us/step - loss: 0.0317 - acc: 0.9899 - val_loss: 0.0263 - val_acc: 0.9918\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 20s 332us/step - loss: 0.0285 - acc: 0.9905 - val_loss: 0.0245 - val_acc: 0.9918\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 20s 330us/step - loss: 0.0270 - acc: 0.9912 - val_loss: 0.0260 - val_acc: 0.9917\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 20s 330us/step - loss: 0.0243 - acc: 0.9919 - val_loss: 0.0257 - val_acc: 0.9922\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 20s 331us/step - loss: 0.0239 - acc: 0.9922 - val_loss: 0.0220 - val_acc: 0.9930\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 20s 331us/step - loss: 0.0223 - acc: 0.9927 - val_loss: 0.0224 - val_acc: 0.9926\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0211 - acc: 0.9931 - val_loss: 0.0261 - val_acc: 0.9929\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 20s 328us/step - loss: 0.0212 - acc: 0.9931 - val_loss: 0.0227 - val_acc: 0.9932\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 20s 328us/step - loss: 0.0203 - acc: 0.9932 - val_loss: 0.0230 - val_acc: 0.9931\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0192 - acc: 0.9936 - val_loss: 0.0240 - val_acc: 0.9927\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0196 - acc: 0.9936 - val_loss: 0.0254 - val_acc: 0.9928\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0184 - acc: 0.9938 - val_loss: 0.0235 - val_acc: 0.9916\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 20s 328us/step - loss: 0.0176 - acc: 0.9938 - val_loss: 0.0238 - val_acc: 0.9929\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0175 - acc: 0.9940 - val_loss: 0.0217 - val_acc: 0.9930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f33e1691f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d_xafjSJNqu",
        "colab_type": "text"
      },
      "source": [
        "## Inference\n",
        "The accuracy is now very close to our target. Now we will increase the batch size and see if we can achieve the target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmoo9SWeKSx0",
        "colab_type": "text"
      },
      "source": [
        "# Iteration 4: Increasing Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENMoxQVz9zN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c13bfb99-35b1-4b7b-b6f3-bfb22eddcc17"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # output 11\n",
        "model.add(Convolution2D(11, 1, activation='relu')) # output 11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(7, 1, activation='relu')) # output 7\n",
        "model.add(Convolution2D(10, 7))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "          \n",
        "model.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_130 (Conv2D)          (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_131 (Conv2D)          (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_132 (Conv2D)          (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_133 (Conv2D)          (None, 11, 11, 11)        187       \n",
            "_________________________________________________________________\n",
            "conv2d_134 (Conv2D)          (None, 9, 9, 16)          1600      \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_135 (Conv2D)          (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_136 (Conv2D)          (None, 7, 7, 7)           119       \n",
            "_________________________________________________________________\n",
            "conv2d_137 (Conv2D)          (None, 1, 1, 10)          3440      \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,786\n",
            "Trainable params: 12,626\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws9rGkfL9zQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9621ffa9-70a6-40e1-ed79-068d8fd977bb"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0323 - acc: 0.9893 - val_loss: 0.0280 - val_acc: 0.9911\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0264 - acc: 0.9914 - val_loss: 0.0268 - val_acc: 0.9924\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0248 - val_acc: 0.9927\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0199 - acc: 0.9936 - val_loss: 0.0225 - val_acc: 0.9928\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0211 - acc: 0.9930 - val_loss: 0.0252 - val_acc: 0.9915\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0179 - acc: 0.9940 - val_loss: 0.0221 - val_acc: 0.9936\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0227 - val_acc: 0.9936\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0152 - acc: 0.9948 - val_loss: 0.0207 - val_acc: 0.9938\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0155 - acc: 0.9948 - val_loss: 0.0248 - val_acc: 0.9931\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0208 - val_acc: 0.9936\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0141 - acc: 0.9952 - val_loss: 0.0200 - val_acc: 0.9937\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0211 - val_acc: 0.9935\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0133 - acc: 0.9954 - val_loss: 0.0211 - val_acc: 0.9937\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0142 - acc: 0.9954 - val_loss: 0.0218 - val_acc: 0.9939\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0133 - acc: 0.9956 - val_loss: 0.0203 - val_acc: 0.9943\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0129 - acc: 0.9959 - val_loss: 0.0200 - val_acc: 0.9944\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0126 - acc: 0.9957 - val_loss: 0.0211 - val_acc: 0.9939\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0225 - val_acc: 0.9939\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0117 - acc: 0.9961 - val_loss: 0.0210 - val_acc: 0.9942\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0202 - val_acc: 0.9945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f33dddb98d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jwAQBvp9zTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "# validation score on test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "ecfa7900-47ec-404f-f021-da3579453bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.020153841206946528, 0.9945]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHuCNmUPMNL3",
        "colab_type": "text"
      },
      "source": [
        "## Inference\n",
        "Now we are able to achieve the validation accuracy of 99.43% at the 15th epoch, this model is able perform very good in-terms of validation accuracy and has only around ~12k paramters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "46cc06a7-d399-4b81-8442-cdad314a8a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])\n",
        "\n",
        "# As we can see below the number indicating the class in each of the arrays listed below, is close to 1 and all the other numbers are far less than that"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.9698393e-15 6.7782857e-10 1.6475249e-07 1.1916333e-06 1.0738651e-16\n",
            "  1.1857919e-11 1.3734541e-21 9.9999869e-01 1.8773664e-15 2.9348298e-11]\n",
            " [2.9721283e-09 1.0249179e-07 9.9999988e-01 2.9843156e-11 9.1723379e-11\n",
            "  9.7138519e-13 4.0947114e-08 9.5490347e-13 4.0707052e-11 1.2695279e-12]\n",
            " [6.0045783e-12 9.9999833e-01 2.6390487e-07 9.6428963e-09 2.6385361e-08\n",
            "  3.6833811e-08 2.9401375e-09 1.3873964e-06 1.3563564e-08 2.1557933e-10]\n",
            " [9.9999917e-01 7.1562710e-17 8.0087426e-10 2.8677864e-11 4.2069594e-11\n",
            "  1.4833869e-08 2.8769415e-07 5.0200612e-12 4.2471041e-10 5.1243461e-07]\n",
            " [6.6160734e-14 4.0008396e-13 3.0173520e-11 1.0872198e-15 9.9999809e-01\n",
            "  1.8131473e-15 1.4212305e-10 1.3057333e-09 2.4110268e-11 1.9049063e-06]\n",
            " [3.8365470e-12 9.9999905e-01 4.7741135e-08 1.2498179e-09 4.9063448e-08\n",
            "  6.8025239e-09 1.6854714e-09 8.4592040e-07 1.6670525e-09 9.2123933e-11]\n",
            " [2.7879544e-18 3.0043142e-11 9.7748525e-11 1.2373911e-13 9.9999917e-01\n",
            "  1.7943837e-13 1.6106924e-16 1.3091711e-09 1.9025508e-07 5.8648141e-07]\n",
            " [4.1507274e-15 1.6721366e-11 4.9481534e-09 8.7206092e-10 6.1088408e-06\n",
            "  6.4184391e-09 2.0440028e-14 2.6316146e-10 5.4863813e-07 9.9999332e-01]\n",
            " [1.5103041e-10 1.4520518e-14 5.3871994e-11 1.8340335e-13 4.6183751e-16\n",
            "  9.6875161e-01 3.1221544e-02 7.9075012e-13 2.6845002e-05 4.0827363e-08]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "\n",
        "# Storing model architecture to a dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "outputId": "debe486b-909f-430b-c0f9-be4812adc0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_131'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAALUCAYAAACre8XKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAoIeOAgAAAICe/wfVygvDLPIWTAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x864 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APdZCw-zDmMM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}