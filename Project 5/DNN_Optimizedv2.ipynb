{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1st DNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarvan0506/AI/blob/Dev/Project%205/DNN_Optimizedv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "# install and import keras for neural network design and implementation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# import keras objects for Convolution and import the dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "18945989-b6e0-4f0c-af85-49c30497b594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# load the datset into train and test sets"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "4671960c-4c65-4259-ef8f-4d56909c77b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])\n",
        "\n",
        "# plotting a sample as image to get a visual feel"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7869c797b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
        "\n",
        "# reshaping the dataset to Convolution format, X_train.shape[0] --> # of images, (28, 28) --> input image resolution, 1 - # of channels(the image itself)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# converting the values into greyscale values."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "e9d4d8a2-f086-473a-dd91-e121c4a26507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRuPQjQZY_0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uniques, ids = np.unique(y_train, return_inverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "c4418c80-701c-4ef6-b5f2-8bad23fafc9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV-W5WqTnnWw",
        "colab_type": "text"
      },
      "source": [
        "Now we are going to optimize the network step by step to achieve max validation accuracy with less no. of parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmoo9SWeKSx0",
        "colab_type": "text"
      },
      "source": [
        "# Good Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENMoxQVz9zN1",
        "colab_type": "code",
        "outputId": "c13bfb99-35b1-4b7b-b6f3-bfb22eddcc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # output 11\n",
        "model.add(Convolution2D(11, 1, activation='relu')) # output 11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(7, 1, activation='relu')) # output 7\n",
        "model.add(Convolution2D(10, 7))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "          \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_130 (Conv2D)          (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_131 (Conv2D)          (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_132 (Conv2D)          (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_133 (Conv2D)          (None, 11, 11, 11)        187       \n",
            "_________________________________________________________________\n",
            "conv2d_134 (Conv2D)          (None, 9, 9, 16)          1600      \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_135 (Conv2D)          (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_136 (Conv2D)          (None, 7, 7, 7)           119       \n",
            "_________________________________________________________________\n",
            "conv2d_137 (Conv2D)          (None, 1, 1, 10)          3440      \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,786\n",
            "Trainable params: 12,626\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws9rGkfL9zQZ",
        "colab_type": "code",
        "outputId": "9621ffa9-70a6-40e1-ed79-068d8fd977bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0323 - acc: 0.9893 - val_loss: 0.0280 - val_acc: 0.9911\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0264 - acc: 0.9914 - val_loss: 0.0268 - val_acc: 0.9924\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0248 - val_acc: 0.9927\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0199 - acc: 0.9936 - val_loss: 0.0225 - val_acc: 0.9928\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0211 - acc: 0.9930 - val_loss: 0.0252 - val_acc: 0.9915\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0179 - acc: 0.9940 - val_loss: 0.0221 - val_acc: 0.9936\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0227 - val_acc: 0.9936\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0152 - acc: 0.9948 - val_loss: 0.0207 - val_acc: 0.9938\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0155 - acc: 0.9948 - val_loss: 0.0248 - val_acc: 0.9931\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0208 - val_acc: 0.9936\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0141 - acc: 0.9952 - val_loss: 0.0200 - val_acc: 0.9937\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0211 - val_acc: 0.9935\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0133 - acc: 0.9954 - val_loss: 0.0211 - val_acc: 0.9937\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0142 - acc: 0.9954 - val_loss: 0.0218 - val_acc: 0.9939\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0133 - acc: 0.9956 - val_loss: 0.0203 - val_acc: 0.9943\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0129 - acc: 0.9959 - val_loss: 0.0200 - val_acc: 0.9944\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0126 - acc: 0.9957 - val_loss: 0.0211 - val_acc: 0.9939\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0225 - val_acc: 0.9939\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0117 - acc: 0.9961 - val_loss: 0.0210 - val_acc: 0.9942\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0202 - val_acc: 0.9945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f33dddb98d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jwAQBvp9zTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "# validation score on test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "ecfa7900-47ec-404f-f021-da3579453bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.020153841206946528, 0.9945]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHuCNmUPMNL3",
        "colab_type": "text"
      },
      "source": [
        "## Inference\n",
        "Now we are able to achieve the validation accuracy of 99.43% at the 15th epoch, this model is able perform very good in-terms of validation accuracy and has only around ~12k paramters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JroLhqz24RaN",
        "colab_type": "text"
      },
      "source": [
        "## Implementing Image Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMh-1B2HzJJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av74R9N88kTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izrroE_B8koe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator = datagen.flow(X_train, Y_train, batch_size=64)\n",
        "test_iterator = datagen.flow(X_test, Y_test, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G3hpdvS-W9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "e5c7b76e-d1ad-4f6d-988d-c764d65c9155"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #24\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 22\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # output 11\n",
        "model.add(Convolution2D(11, 1, activation='relu')) # output 11\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 9\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # output 7\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(7, 1, activation='relu')) # output 7\n",
        "model.add(Convolution2D(10, 7))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "          \n",
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 11, 11, 11)        187       \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 11, 11, 11)        44        \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 9, 9, 16)          1600      \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 7, 7, 7)           119       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 1, 1, 10)          3440      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,702\n",
            "Trainable params: 12,584\n",
            "Non-trainable params: 118\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viyJbnDgBkVV",
        "colab_type": "text"
      },
      "source": [
        "# Adding Weight Decay to total loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlwtQ8uD-XqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def loss_with_reg(model, batch_size, _lambda = 0.001):\n",
        "  reg_loss_sqr = 0\n",
        "  for layer in model.layers:\n",
        "    if len(layer.get_weights()) > 0:\n",
        "      reg_loss_sqr += np.sum(layer.get_weights()[0]**2)\n",
        "  reg_loss_sqr = reg_loss_sqr * (_lambda/2*batch_size)\n",
        "  \n",
        "  def temp(y_true, y_pred):\n",
        "    return K.categorical_crossentrophy(y_true, y_pred) + reg_loss_sqr\n",
        "  return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1so3gK9a-Xts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAin7cqdEXua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64deec3f-99c0-4e6b-8777-fedef422003d"
      },
      "source": [
        "loss_with_reg(model=model, batch_size=64)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.loss_with_reg.<locals>.temp>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lYNQ0jb-XBH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dad77db1-52a3-4e1f-a16b-85f26520d625"
      },
      "source": [
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=40, validation_data=test_iterator, callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 1.0705 - acc: 0.6594 - val_loss: 0.2965 - val_acc: 0.9122\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.2745 - acc: 0.9161 - val_loss: 0.1920 - val_acc: 0.9427\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.2079 - acc: 0.9356 - val_loss: 0.1682 - val_acc: 0.9491\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1795 - acc: 0.9437 - val_loss: 0.1445 - val_acc: 0.9568\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1618 - acc: 0.9502 - val_loss: 0.1375 - val_acc: 0.9573\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1498 - acc: 0.9533 - val_loss: 0.1203 - val_acc: 0.9621\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 0.1432 - acc: 0.9559 - val_loss: 0.1155 - val_acc: 0.9635\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 0.1366 - acc: 0.9581 - val_loss: 0.1125 - val_acc: 0.9651\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1306 - acc: 0.9590 - val_loss: 0.1040 - val_acc: 0.9680\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1249 - acc: 0.9608 - val_loss: 0.1101 - val_acc: 0.9663\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1229 - acc: 0.9619 - val_loss: 0.1019 - val_acc: 0.9687\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1199 - acc: 0.9630 - val_loss: 0.0980 - val_acc: 0.9694\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1195 - acc: 0.9631 - val_loss: 0.0941 - val_acc: 0.9709\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1161 - acc: 0.9631 - val_loss: 0.0932 - val_acc: 0.9709\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 0.1134 - acc: 0.9648 - val_loss: 0.0921 - val_acc: 0.9711\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1118 - acc: 0.9648 - val_loss: 0.0898 - val_acc: 0.9715\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1083 - acc: 0.9670 - val_loss: 0.0887 - val_acc: 0.9725\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1082 - acc: 0.9668 - val_loss: 0.0882 - val_acc: 0.9727\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1070 - acc: 0.9670 - val_loss: 0.0877 - val_acc: 0.9729\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 0.1069 - acc: 0.9673 - val_loss: 0.0859 - val_acc: 0.9731\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1045 - acc: 0.9680 - val_loss: 0.0820 - val_acc: 0.9741\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1043 - acc: 0.9682 - val_loss: 0.0828 - val_acc: 0.9743\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1033 - acc: 0.9684 - val_loss: 0.0824 - val_acc: 0.9743\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1011 - acc: 0.9685 - val_loss: 0.0828 - val_acc: 0.9744\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.1000 - acc: 0.9692 - val_loss: 0.0813 - val_acc: 0.9745\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0998 - acc: 0.9692 - val_loss: 0.0816 - val_acc: 0.9744\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0993 - acc: 0.9690 - val_loss: 0.0815 - val_acc: 0.9740\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0987 - acc: 0.9692 - val_loss: 0.0805 - val_acc: 0.9753\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0974 - acc: 0.9693 - val_loss: 0.0787 - val_acc: 0.9755\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0968 - acc: 0.9698 - val_loss: 0.0768 - val_acc: 0.9754\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0950 - acc: 0.9702 - val_loss: 0.0764 - val_acc: 0.9757\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0976 - acc: 0.9696 - val_loss: 0.0777 - val_acc: 0.9760\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0944 - acc: 0.9710 - val_loss: 0.0741 - val_acc: 0.9762\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0950 - acc: 0.9704 - val_loss: 0.0752 - val_acc: 0.9762\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0928 - acc: 0.9717 - val_loss: 0.0757 - val_acc: 0.9764\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 0.0932 - acc: 0.9712 - val_loss: 0.0755 - val_acc: 0.9763\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0938 - acc: 0.9708 - val_loss: 0.0754 - val_acc: 0.9759\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0920 - acc: 0.9716 - val_loss: 0.0742 - val_acc: 0.9765\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0922 - acc: 0.9713 - val_loss: 0.0739 - val_acc: 0.9766\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0919 - acc: 0.9709 - val_loss: 0.0720 - val_acc: 0.9770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7817516da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rncWUqmjYWek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = uniques[y_pred.argmax(1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIZTpYXdZQcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = np.absolute(y_pred, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBDKou5jZ9go",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3755b17e-cbb9-4eb1-87f7-1869116e7f97"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 6, 1, ..., 4, 6, 6], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZXE1h-8Z9kC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d3e369a-6de7-4a34-e026-42a080297596"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 6, 1, ..., 4, 6, 6], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UsCAuZxZ2M3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = y_pred - y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPUJu23JaKEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50c192fe-c58f-4df2-c251-abfb312bae90"
      },
      "source": [
        "result[result > 0]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "d36d7c35-caf3-45e2-9595-0325305412db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])\n",
        "\n",
        "# As we can see below the number indicating the class in each of the arrays listed below, is close to 1 and all the other numbers are far less than that"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.0103780e-02 5.5292839e-01 4.1684933e-02 3.9381793e-04 6.7190349e-02\n",
            "  5.3466170e-05 8.7737637e-03 2.7841574e-01 6.4954474e-03 1.3960227e-02]\n",
            " [1.4976776e-01 9.8496661e-02 5.8535370e-03 4.4536835e-05 1.4297341e-01\n",
            "  1.3127922e-04 5.9600627e-01 2.1813116e-04 5.6376858e-03 8.7072368e-04]\n",
            " [7.1392404e-03 7.7584833e-01 6.4662221e-04 8.7560138e-06 1.2552966e-01\n",
            "  4.1214895e-05 8.6697616e-02 1.2339101e-03 2.1180008e-03 7.3665241e-04]\n",
            " [2.2056267e-01 1.8928992e-02 1.3051017e-03 3.5824464e-06 1.6643669e-01\n",
            "  2.0989528e-05 5.8776450e-01 1.0980284e-03 1.5825871e-03 2.2968510e-03]\n",
            " [5.0486089e-03 8.2935445e-02 2.1813528e-04 1.1292489e-05 8.5523272e-01\n",
            "  2.8117955e-05 4.8087161e-02 2.9180681e-03 5.0582498e-04 5.0146617e-03]\n",
            " [3.5657752e-03 8.4921014e-01 3.5416801e-04 4.3022260e-06 8.6776018e-02\n",
            "  2.4620827e-05 5.7706315e-02 7.5971481e-04 1.2477664e-03 3.5118323e-04]\n",
            " [2.5770015e-03 5.0047487e-01 1.7758667e-03 3.5480924e-05 4.5635906e-01\n",
            "  1.0070636e-04 2.0471212e-02 2.9281257e-03 7.4855220e-03 7.7920887e-03]\n",
            " [7.8748763e-03 1.2319219e-01 3.5125209e-04 2.6623522e-05 8.0775970e-01\n",
            "  1.1374574e-04 4.9015250e-02 2.2394541e-03 1.5492057e-03 7.8776218e-03]\n",
            " [6.1156515e-02 3.1063143e-02 2.9319106e-03 1.8951891e-05 6.6488206e-02\n",
            "  1.1270987e-03 7.6047182e-01 5.8226846e-03 4.4850167e-03 6.6434644e-02]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma3TEPHyXMI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1kjnZHRXANY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "53eca6b2-0d04-43cc-bb75-eb4878b8b64f"
      },
      "source": [
        "result = np.absolute(y_pred-y_test)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-9b3520f626f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10000,10) (10000,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-QLunIqXAQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e7c5fed9-b0e4-49cb-810d-02dee6140dff"
      },
      "source": [
        "result"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.0103780e-02, 5.5292839e-01, 4.1684933e-02, ..., 7.2158426e-01,\n",
              "        6.4954474e-03, 1.3960227e-02],\n",
              "       [1.4976776e-01, 9.8496661e-02, 9.9414647e-01, ..., 2.1813116e-04,\n",
              "        5.6376858e-03, 8.7072368e-04],\n",
              "       [7.1392404e-03, 2.2415167e-01, 6.4662221e-04, ..., 1.2339101e-03,\n",
              "        2.1180008e-03, 7.3665241e-04],\n",
              "       ...,\n",
              "       [1.1698172e-03, 2.0669070e-01, 6.9033755e-05, ..., 1.1854423e-03,\n",
              "        5.8079086e-04, 1.0023918e-03],\n",
              "       [6.0106024e-02, 2.1340562e-01, 1.0351893e-03, ..., 1.7857789e-03,\n",
              "        6.5871272e-03, 5.7041687e-03],\n",
              "       [5.5034328e-02, 2.4846183e-02, 1.7669224e-03, ..., 3.0172389e-04,\n",
              "        4.3356663e-04, 1.1429824e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "\n",
        "# Storing model architecture to a dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "outputId": "9ded4942-a302-4693-f03c-04c5453edf55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_25'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAALUCAYAAACre8XKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw0ABAAAAQA0DBQAAAAA1DBQAAAAA1Px/ZQi7/rua8CYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x864 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APdZCw-zDmMM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}